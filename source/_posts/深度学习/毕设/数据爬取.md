---
title: 数据爬取
date: 2021-01-04 15:19:54
tags: 爬虫
categories: 毕设
top: 94
---

## 微博爬虫

格式有点乱，很多内容未记录，后面整理

### 1、站点分析

① 目标网站
[微博高级搜索](https://s.weibo.com/)

<!--more-->s
![](https://blog-1257711631.cos.ap-nanjing.myqcloud.com/markdownpic/20210106150826.png)
② 网站测试
* 通过输入发现网站的数据都是通过ajax进行数据传输的，所以没办法直接根据url进行爬取
* 可以直接通过关键字搜索得到结果，然后评论要根据微博mid或者点击获取

### 2、爬取策略

* 使用selenium实现高级搜索
* 先爬取热门的微博20条
* 然后针对每条微博，通过selenium实现评论爬取，这里对评论的爬取可以利用ajax，具体后面再分析


### 3、尝试

#### ① 关键字搜索

* 首先查看网站url，发现搜索页面的url和搜索结果的url无法匹配，这里也无法进行参数构造，所以选择使用selenium进行自动化爬取
* 然后通过selenium定位到关键字的前十条weibo，然后发现评论是ajax数据，需要动态刷新，然后通过chrome的控制台查看ajax数据分析，发现数据url是拼接的，所以可以不使用selenium,而通过请求抓取和构造url进行爬取


#### ② 评论数据抓取

* 这里基于scrapy构建爬取



### 4、部署


## 知乎爬虫

### 问题记录

- 直接访问知乎网站会跳转到登录页面。需要记录登录状态
- 请求搜索api需要解决js加密问题x-zse-86
- 使用selenium构造cookie需要设置name+value形式
- selenium访问搜索结果返回无数据
- 发现selenium访问搜索界面也是通过调用api实现。所以还要走js加密问题
- 发现爬取过程中的异步问题

## 数据处理

使用w3lib库去除text中的一些html标签和特殊字符

## 数据存储

使用mongodb数据库，在docker中部署，然后在scrapy中的pipeline中进行数据的存储

