---
title: 各类网页选择器的使用
date: 2021-01-06 10:10:30
tags: 爬虫
categories: 爬虫
---

## 一、xpath

xpath支持`id`、 `name`、 `class`、 `属性`定位

### 1、xpath语法

![](https://blog-1257711631.cos.ap-nanjing.myqcloud.com/markdownpic/xpath.png)

例子:
![](https://blog-1257711631.cos.ap-nanjing.myqcloud.com/markdownpic/xpath%E4%BE%8B%E5%AD%90.png)


### 2、选取未知节点

![](https://blog-1257711631.cos.ap-nanjing.myqcloud.com/markdownpic/20210106102503.png)

### 3、选取路径

![](https://blog-1257711631.cos.ap-nanjing.myqcloud.com/markdownpic/20210106102847.png)

### 4、读取文本

```python
    result = html.xpath('//li[@class="item-0"]/a/text()')#获取a节点内的文本
    result = html.xpath('//li[@class="item-0"]/text()')#获取为换行符，因为li中还有a节点，这样获取的文本为最后的换行符
    result = html.xpath('//li[@class="item-0"]//text()')#获取结果包括换行符及a内的文本
    
```

### 5、属性多值匹配

```python
    result = html.xpath('//li[contains(@class, "li")]/a/text()')#使用contains()函数
    # 也可以使用contains(text(),"文本")实现文本查找
```

```python
    result = html.xpath('//li[contains(@class, "li") and @name="item"]/a/text()')#这里也可以使用其它运算符如or、mod
```

```python

    result = html.xpath('//li[starts-with(@class, "li")]'）#匹配以属性开头的节点
    result = html.xpath('//li[ends-with(@class, "li")]'）#匹配以属性结尾的节点
```

### 6、节点轴

```python
    result = html.xpath('//li[1]/ancestor::*')#选取所有祖先
    result = html.xpath('//li[1]/ancestor::div')#选取特定祖先
    result = html.xpath('//li[1]/attribute::*')#获取所有属性
    result = html.xpath('//li[1]/child::a[@href="link1.html"]')#获取特定属性限制的直接子节点
    result = html.xpath('//li[1]/descendant::span')#获取特定的子孙节点
    result = html.xpath('//li[1]/following::*[2]')#获取后序两个节点
    result = html.xpath('//li[1]/following-sibling::*')#获取后序所有同级节点
```

### 7、scrapy中的使用

* 在parse(self,response)函数中使用`response.xpath()`
* 使用上述获取的结果是一个列表，可以使用以下的提取方式
    * .getall() 获取所有字符串结果列表
    * .get() 获取第一个字符串结果
    * .extract_first()/.extract() 旧方法



## 二、正则表达式

### 1、正则表达式基本规则
规则:
![](https://blog-1257711631.cos.ap-nanjing.myqcloud.com/markdownpic/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F.png)
修饰符:
![](https://blog-1257711631.cos.ap-nanjing.myqcloud.com/markdownpic/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%BF%AE%E9%A5%B0%E7%AC%A6.png)

### 2、匹配目标
```python
  import re
  content = 'Hello 1234567 World_This is a Regex Demo'
  result = re.match('^Hello\s(\d+)\sWorld', content)
  print(result)
  print(result.group())
  print(result.group(1))
  print(result.span())
```
```
  输出
  <re.Match object; span=(0, 19), match='Hello 1234567 World'>
  Hello 1234567 World
  1234567
  (0, 19)
```
### 2、通用匹配
```python
  result = re.match('^Hello.*Demo$', content)
  #.*表示代替所有字符包括空格，但是要加上结束字符
```
### 3、贪婪与非贪婪(？的差别)
    贪婪匹配尽可能多的匹配字符，而非贪婪是尽可能少的匹配
```python
  #注意当匹配结果在结尾时非贪婪会匹配不到内容
  import re

  content = 'http://weibo.com/comment/kEraCN'
  result1 = re.match('http.*?comment/(.*?)', content)
  result2 = re.match('http.*?comment/(.*)', content)
  print('result1', result1.group(1))
  print('result2', result2.group(1))
```
```
  输出
  result1
  result2 kEraCN
```

### 4、修饰符(主要是re.S经常用到用来处理有换行节点的html)
### 5、转义匹配
```python
  import re

  content = '(百度)www.baidu.com'
  result = re.match('\(百度\)www\.baidu\.com', content)
  print(result)
```
```
  输出
  <re.Match object; span=(0, 17), match='(百度)www.baidu.com'>
```

### 5、findall()和sub()

`findall()`返回匹配的所有结果

`sub()`删除结果中指定内容
```python
  import re

  content = '54aK54yr5oiR54ix5L2g'
  content = re.sub('\d+', '', content)
  print(content)
```

### 6、complie()

```python
import re

key = r"chuxiuhong@hit.edu.cn"
p1 = r"@.+?\."#我想匹配到@后面一直到“.”之间的，在这里是hit
pattern1 = re.compile(p1)
print pattern1.findall(key)
```

### 7、scrapy中的应用

